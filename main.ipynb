{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "import time as t\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from itertools import chain\n",
    "from torchvision import utils\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time as t\n",
    "import os\n",
    "from itertools import chain\n",
    "from torchvision import utils\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "from torchvision.models.inception import inception_v3\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import torch\n",
    "import codecs\n",
    "\n",
    "# Code referenced from torch source code to add Fashion-MNSIT dataset to dataloder\n",
    "# Url: http://pytorch.org/docs/0.3.0/_modules/torchvision/datasets/mnist.html#FashionMNIST\n",
    "class MNIST(data.Dataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # download files\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                    gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            os.unlink(file_path)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "\n",
    "class FashionMNIST(MNIST):\n",
    "    \"\"\"`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "\n",
    "def parse_byte(b):\n",
    "    if isinstance(b, str):\n",
    "        return ord(b)\n",
    "    return b\n",
    "\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        labels = [parse_byte(b) for b in data[8:]]\n",
    "        assert len(labels) == length\n",
    "        return torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        images = []\n",
    "        idx = 16\n",
    "        for l in range(length):\n",
    "            img = []\n",
    "            images.append(img)\n",
    "            for r in range(num_rows):\n",
    "                row = []\n",
    "                img.append(row)\n",
    "                for c in range(num_cols):\n",
    "                    row.append(parse_byte(data[idx]))\n",
    "                    idx += 1\n",
    "        assert len(images) == length\n",
    "        return torch.ByteTensor(images).view(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "def get_data_loader(args):\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ])\n",
    "    train_dataset = FashionMNIST(root=args.dataroot, train=True, download=args.download, transform=trans)\n",
    "    test_dataset = FashionMNIST(root=args.dataroot, train=False, download=args.download, transform=trans)\n",
    "\n",
    "    train_dataloader = data_utils.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    test_dataloader = data_utils.DataLoader(test_dataset,  batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
    "    \"\"\"\n",
    "        Computes the inception score of the generated images imgs\n",
    "        imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
    "        cuda -- whether or not to run on GPU\n",
    "        batch_size -- batch size for feeding into Inception v3\n",
    "        splits -- number of splits\n",
    "    \"\"\"\n",
    "    N = len(imgs)\n",
    "\n",
    "    assert batch_size > 0\n",
    "    assert N > batch_size\n",
    "\n",
    "    # Set up dtype\n",
    "    if cuda:\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # Set up dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
    "\n",
    "    # Load inception model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
    "    inception_model.eval();\n",
    "    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = up(x)\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "    # Get predictions\n",
    "    preds = np.zeros((N, 1000))\n",
    "\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        batch = batch.type(dtype)\n",
    "        batchv = Variable(batch)\n",
    "        batch_size_i = batch.size()[0]\n",
    "\n",
    "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
    "\n",
    "    # Now compute the mean kl-div\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_Generator(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        # Filters [1024, 512, 256]\n",
    "        # Input_dim = 100\n",
    "        # Output_dim = C (number of channels)\n",
    "        self.main_module = nn.Sequential(\n",
    "            # Z latent vector 100\n",
    "            nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=1024),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (1024x4x4)\n",
    "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (512x8x8)\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (256x16x16)\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=channels, kernel_size=4, stride=2, padding=1))\n",
    "            # output of main module --> Image (Cx32x32)\n",
    "\n",
    "        self.output = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main_module(x)\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "class DCGAN_Discriminator(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        # Filters [256, 512, 1024]\n",
    "        # Input_dim = channels (Cx64x64)\n",
    "        # Output_dim = 1\n",
    "        self.main_module = nn.Sequential(\n",
    "            # Image (Cx32x32)\n",
    "            nn.Conv2d(in_channels=channels, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # State (256x16x16)\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # State (512x8x8)\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True))\n",
    "            # outptut of main module --> State (1024x4x4)\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0),\n",
    "            # Output 1\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main_module(x)\n",
    "        return self.output(x)\n",
    "\n",
    "    def feature_extraction(self, x):\n",
    "        # Use discriminator for feature extraction then flatten to vector of 16384 features\n",
    "        x = self.main_module(x)\n",
    "        return x.view(-1, 1024*4*4)\n",
    "\n",
    "class DCGAN_MODEL(object):\n",
    "    def __init__(self, args):\n",
    "        print(\"DCGAN model initalization.\")\n",
    "        self.G = DCGAN_Generator(args.channels)\n",
    "        self.D = DCGAN_Discriminator(args.channels)\n",
    "        self.C = args.channels\n",
    "\n",
    "        # binary cross entropy loss and optimizer\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        self.cuda = False\n",
    "        self.cuda_index = 0\n",
    "        # check if cuda is available\n",
    "        self.check_cuda(args.cuda)\n",
    "\n",
    "        # Using lower learning rate than suggested by (ADAM authors) lr=0.0002  and Beta_1 = 0.5 instead od 0.9 works better [Radford2015]\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "        self.epochs = args.epochs\n",
    "        self.batch_size = args.batch_size\n",
    "\n",
    "        self.number_of_images = 10\n",
    "\n",
    "    # cuda support\n",
    "    def check_cuda(self, cuda_flag=False):\n",
    "        if cuda_flag:\n",
    "            self.cuda = True\n",
    "            self.D.cuda(self.cuda_index)\n",
    "            self.G.cuda(self.cuda_index)\n",
    "            self.loss = nn.BCELoss().cuda(self.cuda_index)\n",
    "            print(\"Cuda enabled flag: \")\n",
    "            print(self.cuda)\n",
    "\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        self.t_begin = t.time()\n",
    "        generator_iter = 0\n",
    "        #self.file = open(\"inception_score_graph.txt\", \"w\")\n",
    "        g_res = []\n",
    "        d_res = []\n",
    "        for epoch in range(self.epochs):\n",
    "            self.epoch_start_time = t.time()\n",
    "\n",
    "            for i, (images, _) in enumerate(train_loader):\n",
    "                # Check if round number of batches\n",
    "                if i == train_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                z = torch.rand((self.batch_size, 100, 1, 1))\n",
    "                real_labels = torch.ones(self.batch_size)\n",
    "                fake_labels = torch.zeros(self.batch_size)\n",
    "\n",
    "                if self.cuda:\n",
    "                    images, z = Variable(images).cuda(self.cuda_index), Variable(z).cuda(self.cuda_index)\n",
    "                    real_labels, fake_labels = Variable(real_labels).cuda(self.cuda_index), Variable(fake_labels).cuda(self.cuda_index)\n",
    "                else:\n",
    "                    images, z = Variable(images), Variable(z)\n",
    "                    real_labels, fake_labels = Variable(real_labels), Variable(fake_labels)\n",
    "\n",
    "\n",
    "                # Train discriminator\n",
    "                # Compute BCE_Loss using real images\n",
    "                outputs = self.D(images)\n",
    "                d_loss_real = self.loss(outputs.flatten(), real_labels)\n",
    "                real_score = outputs\n",
    "\n",
    "                # Compute BCE Loss using fake images\n",
    "                if self.cuda:\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1)).cuda(self.cuda_index)\n",
    "                else:\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1))\n",
    "                fake_images = self.G(z)\n",
    "                outputs = self.D(fake_images)\n",
    "                d_loss_fake = self.loss(outputs.flatten(), fake_labels)\n",
    "                fake_score = outputs\n",
    "\n",
    "                # Optimize discriminator\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "                self.D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Train generator\n",
    "                # Compute loss with fake images\n",
    "                if self.cuda:\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1)).cuda(self.cuda_index)\n",
    "                else:\n",
    "                    z = Variable(torch.randn(self.batch_size, 100, 1, 1))\n",
    "                fake_images = self.G(z)\n",
    "                outputs = self.D(fake_images)\n",
    "                g_loss = self.loss(outputs.flatten(), real_labels)\n",
    "\n",
    "                # Optimize generator\n",
    "                self.D.zero_grad()\n",
    "                self.G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "                generator_iter += 1\n",
    "                print(generator_iter)\n",
    "\n",
    "\n",
    "                if ((i + 1) % ITERATION_NUMS) == 0:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
    "                          ((epoch + 1), (i + 1), train_loader.dataset.__len__() // self.batch_size, d_loss.data, g_loss.data))\n",
    "\n",
    "                    if self.cuda:\n",
    "                        z = Variable(torch.randn(self.batch_size, 100, 1, 1)).cuda(self.cuda_index)\n",
    "                    else:\n",
    "                        z = Variable(torch.randn(self.batch_size, 100, 1, 1))\n",
    "\n",
    "                    # TensorBoard logging\n",
    "                    # Log the scalar values\n",
    "                    d_res.append(d_loss.data)\n",
    "                    g_res.append(g_loss.data)\n",
    "\n",
    "\n",
    "        return d_res,g_res\n",
    "\n",
    "    def evaluate(self, test_loader, D_model_path, G_model_path):\n",
    "        self.load_model(D_model_path, G_model_path)\n",
    "        z = Variable(torch.randn(self.batch_size, 100, 1, 1)).cuda(self.cuda_index)\n",
    "        samples = self.G(z)\n",
    "        samples = samples.mul(0.5).add(0.5)\n",
    "        samples = samples.data.cpu()\n",
    "        grid = utils.make_grid(samples)\n",
    "        print(\"Grid of 8x8 images saved to 'dgan_model_image.png'.\")\n",
    "        utils.save_image(grid, 'dgan_model_image.png')\n",
    "\n",
    "    def real_images(self, images, number_of_images):\n",
    "        if (self.C == 3):\n",
    "            return self.to_np(images.view(-1, self.C, 32, 32)[:self.number_of_images])\n",
    "        else:\n",
    "            return self.to_np(images.view(-1, 32, 32)[:self.number_of_images])\n",
    "\n",
    "    def generate_img(self, z, number_of_images):\n",
    "        samples = self.G(z).data.cpu().numpy()[:number_of_images]\n",
    "        generated_images = []\n",
    "        for sample in samples:\n",
    "            if self.C == 3:\n",
    "                generated_images.append(sample.reshape(self.C, 32, 32))\n",
    "            else:\n",
    "                generated_images.append(sample.reshape(32, 32))\n",
    "        return generated_images\n",
    "\n",
    "    def to_np(self, x):\n",
    "        return x.data.cpu().numpy()\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.G.state_dict(), './generator.pkl')\n",
    "        torch.save(self.D.state_dict(), './discriminator.pkl')\n",
    "        print('Models save to ./generator.pkl & ./discriminator.pkl ')\n",
    "\n",
    "    def load_model(self, D_model_filename, G_model_filename):\n",
    "        D_model_path = os.path.join(os.getcwd(), D_model_filename)\n",
    "        G_model_path = os.path.join(os.getcwd(), G_model_filename)\n",
    "        self.D.load_state_dict(torch.load(D_model_path))\n",
    "        self.G.load_state_dict(torch.load(G_model_path))\n",
    "        print('Generator model loaded from {}.'.format(G_model_path))\n",
    "        print('Discriminator model loaded from {}-'.format(D_model_path))\n",
    "\n",
    "    def generate_latent_walk(self, number):\n",
    "        if not os.path.exists('interpolated_images/'):\n",
    "            os.makedirs('interpolated_images/')\n",
    "\n",
    "        # Interpolate between twe noise(z1, z2) with number_int steps between\n",
    "        number_int = 10\n",
    "        z_intp = torch.FloatTensor(1, 100, 1, 1)\n",
    "        z1 = torch.randn(1, 100, 1, 1)\n",
    "        z2 = torch.randn(1, 100, 1, 1)\n",
    "        if self.cuda:\n",
    "            z_intp = z_intp.cuda()\n",
    "            z1 = z1.cuda()\n",
    "            z2 = z2.cuda()\n",
    "\n",
    "        z_intp = Variable(z_intp)\n",
    "        images = []\n",
    "        alpha = 1.0 / float(number_int + 1)\n",
    "        print(alpha)\n",
    "        for i in range(1, number_int + 1):\n",
    "            z_intp.data = z1*alpha + z2*(1.0 - alpha)\n",
    "            alpha += alpha\n",
    "            fake_im = self.G(z_intp)\n",
    "            fake_im = fake_im.mul(0.5).add(0.5) #denormalize\n",
    "            images.append(fake_im.view(self.C,32,32).data.cpu())\n",
    "\n",
    "        grid = utils.make_grid(images, nrow=number_int )\n",
    "        utils.save_image(grid, 'interpolated_images/interpolated_{}.png'.format(str(number).zfill(3)))\n",
    "        print(\"Saved interpolated images to interpolated_images/interpolated_{}.\".format(str(number).zfill(3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SAVE_PER_TIMES = 100\n",
    "\n",
    "class WGAN_Generator(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        # Filters [1024, 512, 256]\n",
    "        # Input_dim = 100\n",
    "        # Output_dim = C (number of channels)\n",
    "        self.main_module = nn.Sequential(\n",
    "            # Z latent vector 100\n",
    "            nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=1024),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (1024x4x4)\n",
    "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (512x8x8)\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # State (256x16x16)\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=channels, kernel_size=4, stride=2, padding=1))\n",
    "            # output of main module --> Image (Cx32x32)\n",
    "\n",
    "        self.output = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main_module(x)\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "class WGAN_Discriminator(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        # Filters [256, 512, 1024]\n",
    "        # Input_dim = channels (Cx64x64)\n",
    "        # Output_dim = 1\n",
    "        self.main_module = nn.Sequential(\n",
    "            # Omitting batch normalization in critic because our new penalized training objective (WGAN with gradient penalty) is no longer valid\n",
    "            # in this setting, since we penalize the norm of the critic's gradient with respect to each input independently and not the enitre batch.\n",
    "            # There is not good & fast implementation of layer normalization --> using per instance normalization nn.InstanceNorm2d()\n",
    "            # Image (Cx32x32)\n",
    "            nn.Conv2d(in_channels=channels, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # State (256x16x16)\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(512, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # State (512x8x8)\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(1024, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True))\n",
    "            # output of main module --> State (1024x4x4)\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            # The output of D is no longer a probability, we do not apply sigmoid at the output of D.\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main_module(x)\n",
    "        return self.output(x)\n",
    "\n",
    "    def feature_extraction(self, x):\n",
    "        # Use discriminator for feature extraction then flatten to vector of 16384\n",
    "        x = self.main_module(x)\n",
    "        return x.view(-1, 1024*4*4)\n",
    "\n",
    "\n",
    "class WGAN_GP(object):\n",
    "    def __init__(self, args):\n",
    "        print(\"WGAN_GradientPenalty init model.\")\n",
    "        self.G = WGAN_Generator(args.channels)\n",
    "        self.D = WGAN_Discriminator(args.channels)\n",
    "        self.C = args.channels\n",
    "\n",
    "        # Check if cuda is available\n",
    "        self.check_cuda(args.cuda)\n",
    "\n",
    "        # WGAN values from paper\n",
    "        self.learning_rate = 1e-4\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.batch_size = 64\n",
    "\n",
    "        # WGAN_gradient penalty uses ADAM\n",
    "        self.d_optimizer = optim.Adam(self.D.parameters(), lr=self.learning_rate, betas=(self.b1, self.b2))\n",
    "        self.g_optimizer = optim.Adam(self.G.parameters(), lr=self.learning_rate, betas=(self.b1, self.b2))\n",
    "\n",
    "        self.number_of_images = 10\n",
    "\n",
    "        self.generator_iters = args.generator_iters\n",
    "        self.critic_iter = 5\n",
    "        self.lambda_term = 10\n",
    "\n",
    "    def get_torch_variable(self, arg):\n",
    "        if self.cuda:\n",
    "            return Variable(arg).cuda(self.cuda_index)\n",
    "        else:\n",
    "            return Variable(arg)\n",
    "\n",
    "    def check_cuda(self, cuda_flag=False):\n",
    "        print(cuda_flag)\n",
    "        if cuda_flag:\n",
    "            self.cuda_index = 0\n",
    "            self.cuda = True\n",
    "            self.D.cuda(self.cuda_index)\n",
    "            self.G.cuda(self.cuda_index)\n",
    "            print(\"Cuda enabled flag: {}\".format(self.cuda))\n",
    "        else:\n",
    "            self.cuda = False\n",
    "\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        print(\"STARTING\")\n",
    "        # Now batches are callable self.data.next()\n",
    "        self.data = self.get_infinite_batches(train_loader)\n",
    "        g_res = []\n",
    "        d_res = []\n",
    "        one = torch.tensor(1, dtype=torch.float)\n",
    "        mone = one * -1\n",
    "        if self.cuda:\n",
    "            one = one.cuda(self.cuda_index)\n",
    "            mone = mone.cuda(self.cuda_index)\n",
    "\n",
    "        for g_iter in range(self.generator_iters):\n",
    "            # Requires grad, Generator requires_grad = False\n",
    "            for p in self.D.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            d_loss_real = 0\n",
    "            d_loss_fake = 0\n",
    "            Wasserstein_D = 0\n",
    "            # Train Dicriminator forward-loss-backward-update self.critic_iter times while 1 Generator forward-loss-backward-update\n",
    "            for d_iter in range(self.critic_iter):\n",
    "                print(d_iter)\n",
    "                self.D.zero_grad()\n",
    "\n",
    "                images = self.data.__next__()\n",
    "                # Check for batch to have full batch_size\n",
    "                if (images.size()[0] != self.batch_size):\n",
    "                    continue\n",
    "\n",
    "                z = torch.rand((self.batch_size, 100, 1, 1))\n",
    "\n",
    "                images, z = self.get_torch_variable(images), self.get_torch_variable(z)\n",
    "\n",
    "                # Train discriminator\n",
    "                # WGAN - Training discriminator more iterations than generator\n",
    "                # Train with real images\n",
    "                d_loss_real = self.D(images)\n",
    "                d_loss_real = d_loss_real.mean()\n",
    "                d_loss_real.backward(mone)\n",
    "\n",
    "                # Train with fake images\n",
    "                z = self.get_torch_variable(torch.randn(self.batch_size, 100, 1, 1))\n",
    "\n",
    "                fake_images = self.G(z)\n",
    "                d_loss_fake = self.D(fake_images)\n",
    "                d_loss_fake = d_loss_fake.mean()\n",
    "                d_loss_fake.backward(one)\n",
    "\n",
    "                # Train with gradient penalty\n",
    "                gradient_penalty = self.calculate_gradient_penalty(images.data, fake_images.data)\n",
    "                gradient_penalty.backward()\n",
    "\n",
    "\n",
    "                d_loss = d_loss_fake - d_loss_real + gradient_penalty\n",
    "                Wasserstein_D = d_loss_real - d_loss_fake\n",
    "                self.d_optimizer.step()\n",
    "                print(f'  Discriminator iteration: {d_iter}/{self.critic_iter}, loss_fake: {d_loss_fake}, loss_real: {d_loss_real}')\n",
    "\n",
    "            # Generator update\n",
    "            for p in self.D.parameters():\n",
    "                p.requires_grad = False  # to avoid computation\n",
    "\n",
    "            self.G.zero_grad()\n",
    "            # train generator\n",
    "            # compute loss with fake images\n",
    "            z = self.get_torch_variable(torch.randn(self.batch_size, 100, 1, 1))\n",
    "            fake_images = self.G(z)\n",
    "            g_loss = self.D(fake_images)\n",
    "            g_loss = g_loss.mean()\n",
    "            g_loss.backward(mone)\n",
    "            g_cost = -g_loss\n",
    "            self.g_optimizer.step()\n",
    "            \n",
    "            g_res.append(g_loss)\n",
    "            d_res.append(d_loss)\n",
    "            print(f'Generator iteration: {g_iter}/{self.generator_iters}, g_loss: {g_loss}')\n",
    "            # Saving model and sampling images every 1000th generator iterations\n",
    "            if (g_iter) % SAVE_PER_TIMES == 0:\n",
    "\n",
    "\n",
    "                # Denormalize images and save them in grid 8x8\n",
    "                # Testing\n",
    "                #print(\"Real Inception score: {}\".format(inception_score))\n",
    "                print(\"Generator iter: {}\".format(g_iter))\n",
    "\n",
    "        return g_res,d_res\n",
    "\n",
    "\n",
    "    def calculate_gradient_penalty(self, real_images, fake_images):\n",
    "        eta = torch.FloatTensor(self.batch_size,1,1,1).uniform_(0,1)\n",
    "        eta = eta.expand(self.batch_size, real_images.size(1), real_images.size(2), real_images.size(3))\n",
    "        if self.cuda:\n",
    "            eta = eta.cuda(self.cuda_index)\n",
    "        else:\n",
    "            eta = eta\n",
    "\n",
    "        interpolated = eta * real_images + ((1 - eta) * fake_images)\n",
    "\n",
    "        if self.cuda:\n",
    "            interpolated = interpolated.cuda(self.cuda_index)\n",
    "        else:\n",
    "            interpolated = interpolated\n",
    "\n",
    "        # define it to calculate gradient\n",
    "        interpolated = Variable(interpolated, requires_grad=True)\n",
    "\n",
    "        # calculate probability of interpolated examples\n",
    "        prob_interpolated = self.D(interpolated)\n",
    "\n",
    "        # calculate gradients of probabilities with respect to examples\n",
    "        gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                               grad_outputs=torch.ones(\n",
    "                                   prob_interpolated.size()).cuda(self.cuda_index) if self.cuda else torch.ones(\n",
    "                                   prob_interpolated.size()),\n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * self.lambda_term\n",
    "        return grad_penalty\n",
    "\n",
    "    def real_images(self, images, number_of_images):\n",
    "        if (self.C == 3):\n",
    "            return self.to_np(images.view(-1, self.C, 32, 32)[:self.number_of_images])\n",
    "        else:\n",
    "            return self.to_np(images.view(-1, 32, 32)[:self.number_of_images])\n",
    "\n",
    "    def generate_img(self, z, number_of_images):\n",
    "        samples = self.G(z).data.cpu().numpy()[:number_of_images]\n",
    "        generated_images = []\n",
    "        for sample in samples:\n",
    "            if self.C == 3:\n",
    "                generated_images.append(sample.reshape(self.C, 32, 32))\n",
    "            else:\n",
    "                generated_images.append(sample.reshape(32, 32))\n",
    "        return generated_images\n",
    "\n",
    "    def to_np(self, x):\n",
    "        return x.data.cpu().numpy()\n",
    "\n",
    "\n",
    "    def get_infinite_batches(self, data_loader):\n",
    "        while True:\n",
    "            for i, (images, _) in enumerate(data_loader):\n",
    "                yield images\n",
    "\n",
    "    def generate_latent_walk(self, number):\n",
    "        if not os.path.exists('interpolated_images/'):\n",
    "            os.makedirs('interpolated_images/')\n",
    "\n",
    "        number_int = 10\n",
    "        # interpolate between twe noise(z1, z2).\n",
    "        z_intp = torch.FloatTensor(1, 100, 1, 1)\n",
    "        z1 = torch.randn(1, 100, 1, 1)\n",
    "        z2 = torch.randn(1, 100, 1, 1)\n",
    "        if self.cuda:\n",
    "            z_intp = z_intp.cuda()\n",
    "            z1 = z1.cuda()\n",
    "            z2 = z2.cuda()\n",
    "\n",
    "        z_intp = Variable(z_intp)\n",
    "        images = []\n",
    "        alpha = 1.0 / float(number_int + 1)\n",
    "        print(alpha)\n",
    "        for i in range(1, number_int + 1):\n",
    "            z_intp.data = z1*alpha + z2*(1.0 - alpha)\n",
    "            alpha += alpha\n",
    "            fake_im = self.G(z_intp)\n",
    "            fake_im = fake_im.mul(0.5).add(0.5) #denormalize\n",
    "            images.append(fake_im.view(self.C,32,32).data.cpu())\n",
    "\n",
    "        grid = utils.make_grid(images, nrow=number_int )\n",
    "        utils.save_image(grid, 'interpolated_images/interpolated_{}.png'.format(str(number).zfill(3)))\n",
    "        print(\"Saved interpolated images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    model = None\n",
    "    if args.model == 'DCGAN':\n",
    "        model = DCGAN_MODEL(args)\n",
    "    elif args.model == 'WGAN':\n",
    "        model = WGAN_GP(args)\n",
    "    else:\n",
    "        print(\"Model type non-existing. Try again.\")\n",
    "        return 0\n",
    "\n",
    "    print(model)\n",
    "    # Load datasets to train and test loaders\n",
    "    train_loader, test_loader = get_data_loader(args)\n",
    "    #feature_extraction = FeatureExtractionTest(train_loader, test_loader, args.cuda, args.batch_size)\n",
    "\n",
    "    # Start model training\n",
    "    results = model.train(train_loader)\n",
    "    for i in range(5):\n",
    "        model.generate_latent_walk(i)\n",
    "    plt.plot(results[0])\n",
    "    plt.plot(results[1])\n",
    "    plt.show()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "\n",
    "if DEBUG:\n",
    "    ITERS = \"4\"\n",
    "    EPOCHS = \"1\"\n",
    "    CUDA = False\n",
    "    ITERATION_NUMS = 5\n",
    "else:\n",
    "    ITERS = \"40000\"\n",
    "    EPOCHS = \"400\"\n",
    "    ITERATION_NUMS = 100\n",
    "    CUDA = True\n",
    "\n",
    "def parse_args(args=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', type=str, default='DCGAN', choices=['DCGAN', 'WGAN'])\n",
    "    parser.add_argument('--is_train', type=str, default='True')\n",
    "    parser.add_argument('--dataroot', required=True)\n",
    "    parser.add_argument('--dataset', type=str, default='mnist', choices=['fashion-mnist'])\n",
    "    parser.add_argument('--download', type=str, default='False')\n",
    "    parser.add_argument('--epochs', type=int, default=50)\n",
    "    parser.add_argument('--batch_size', type=int, default=64)\n",
    "    parser.add_argument('--cuda',  type=bool, default='False')\n",
    "    parser.add_argument('--load_D', type=str, default='False')\n",
    "    parser.add_argument('--load_G', type=str, default='False')\n",
    "    parser.add_argument('--generator_iters', type=int, default=10000)\n",
    "    parser.add_argument('--channels',type=int,default=1)\n",
    "    return parser.parse_args(args)\n",
    "\n",
    " \n",
    "    \n",
    "wgan_args = [\"--model\", \"WGAN\",\n",
    "           \"--is_train\", \"True\",\n",
    "           \"--epochs\", EPOCHS,\n",
    "           \"--cuda\",CUDA,\n",
    "\n",
    "           \"--download\", \"False\",\n",
    "           \"--dataroot\", \"datasets/fashion-mnist\",\n",
    "           \"--dataset\", \"fashion-mnist\",\n",
    "           \"--generator_iters\", ITERS,\n",
    "           \"--cuda\", \"False\",\n",
    "           \"--batch_size\" ,\"64\"]\n",
    "\n",
    "dcgan_args = [\"--model\", \"DCGAN\",\n",
    "           \"--is_train\", \"True\",\n",
    "           \"--epochs\", EPOCHS,\n",
    "           \"--cuda\",CUDA,\n",
    "           \"--download\", \"False\",\n",
    "           \"--dataroot\", \"datasets/fashion-mnist\",\n",
    "           \"--dataset\", \"fashion-mnist\",\n",
    "           \"--generator_iters\", ITERS,\n",
    "           \"--cuda\", \"False\",\n",
    "           \"--batch_size\" ,\"64\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args(wgan_args)\n",
    "args.cuda = CUDA\n",
    "#results = main(args)\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCGAN model initalization.\n",
      "<__main__.DCGAN_MODEL object at 0x000002513ABF8648>\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Epoch: [ 1] [   5/ 937] D_loss: 0.22256842, G_loss: 12.48026466\n",
      "6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dba6b67e13ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCUDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-1ec435ec99a3>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Start model training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_latent_walk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3e3de0a5ae2d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_loss_real\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                 \u001b[0md_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = parse_args(dcgan_args)\n",
    "args.cuda = CUDA\n",
    "\n",
    "results = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
